<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech & Text Utility | SilenVault</title>
    <meta name="description" content="Local browser-based speech synthesis and dictation utility. Process speech-to-text and text-to-speech with zero cloud dependencies.">
    <meta name="keywords" content="speech to text, text to speech, local dictation, browser speech api, voice synthesizer, transcription tool">
    <meta name="author" content="SilenVault">
    
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@400;500;700&family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <script src="../assets/js/layout.js" defer></script>
    <link rel="stylesheet" href="../assets/css/components.css">

    <style>
        :root { --bg-color: #0f172a; --panel-bg: rgba(30, 41, 59, 0.85); --primary-text: #f8fafc; }
        body { font-family: 'Inter', sans-serif; background-color: var(--bg-color); color: var(--primary-text); overflow-x: hidden; }
        .glass-panel { background: var(--panel-bg); backdrop-filter: blur(16px); border: 1px solid #334155; }
        .mono { font-family: 'Fira Code', monospace; }
        
        /* Custom Range Sliders */
        input[type=range] { -webkit-appearance: none; background: transparent; width: 100%; }
        input[type=range]::-webkit-slider-thumb { -webkit-appearance: none; height: 16px; width: 16px; border-radius: 50%; background: #3b82f6; cursor: pointer; margin-top: -6px; }
        input[type=range]::-webkit-slider-runnable-track { width: 100%; height: 4px; cursor: pointer; background: #334155; border-radius: 2px; }
        
        .recording-pulse { animation: recPulse 1.5s infinite; }
        @keyframes recPulse { 0% { box-shadow: 0 0 0 0 rgba(225, 29, 72, 0.4); } 70% { box-shadow: 0 0 0 15px rgba(225, 29, 72, 0); } 100% { box-shadow: 0 0 0 0 rgba(225, 29, 72, 0); } }
    </style>
</head>
<body class="flex flex-col min-h-screen">

    <sv-header base-path=".."></sv-header>

    <main class="flex-1 max-w-[1200px] mx-auto w-full px-4 py-8 flex flex-col gap-6">
        <div class="mb-4 flex flex-col md:flex-row items-center justify-between gap-4">
            <div>
                <h1 class="text-3xl md:text-4xl font-extrabold text-white tracking-tight">Speech & Text <span class="text-blue-400">Utility</span></h1>
                <p class="text-sm text-slate-400 mt-2">Native browser speech synthesis and dictation. Zero external cloud processing.</p>
            </div>
            <span class="bg-blue-900/30 border border-blue-500/30 text-blue-300 px-3 py-1 rounded text-xs font-bold uppercase tracking-widest hidden md:block">Web Speech API</span>
        </div>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 items-start">
            
            <div class="glass-panel p-6 rounded-2xl shadow-xl flex flex-col gap-4">
                <div class="border-b border-slate-700 pb-3 flex justify-between items-center">
                    <h2 class="text-lg font-bold text-white flex items-center gap-2">
                        <svg class="w-5 h-5 text-blue-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z"/></svg>
                        Text to Speech
                    </h2>
                </div>
                
                <textarea id="tts-input" class="w-full h-40 bg-[#020617] border border-slate-700 rounded-xl p-4 text-sm text-slate-200 focus:outline-none focus:border-blue-500 resize-none shadow-inner" placeholder="Enter text to synthesize into speech..."></textarea>

                <div class="flex flex-col gap-4 bg-slate-900/50 p-4 rounded-xl border border-slate-800">
                    <div class="flex flex-col gap-1">
                        <label class="text-[10px] text-slate-500 font-bold uppercase tracking-widest pl-1">System Voice Profile</label>
                        <select id="voice-select" class="w-full bg-[#020617] border border-slate-700 text-slate-300 text-sm rounded-lg px-3 py-2 outline-none shadow-inner">
                            <option value="">Loading voices...</option>
                        </select>
                    </div>

                    <div class="grid grid-cols-2 gap-6">
                        <div class="flex flex-col gap-2">
                            <div class="flex justify-between items-center">
                                <label class="text-[10px] text-slate-500 font-bold uppercase tracking-widest pl-1">Speed</label>
                                <span id="rate-val" class="text-xs text-blue-400 font-mono">1.0</span>
                            </div>
                            <input type="range" id="rate" min="0.5" max="2" value="1" step="0.1">
                        </div>
                        <div class="flex flex-col gap-2">
                            <div class="flex justify-between items-center">
                                <label class="text-[10px] text-slate-500 font-bold uppercase tracking-widest pl-1">Pitch</label>
                                <span id="pitch-val" class="text-xs text-blue-400 font-mono">1.0</span>
                            </div>
                            <input type="range" id="pitch" min="0" max="2" value="1" step="0.1">
                        </div>
                    </div>
                </div>

                <div class="flex gap-3 mt-2">
                    <button id="btn-speak" onclick="speakText()" class="flex-1 bg-blue-600 hover:bg-blue-500 text-white font-bold py-3 rounded-xl transition-all shadow-lg border border-blue-500 text-sm">
                        Synthesize Audio
                    </button>
                    <button onclick="stopSpeech()" class="bg-slate-800 hover:bg-slate-700 text-slate-300 font-bold px-5 py-3 rounded-xl transition-all border border-slate-600 text-sm">
                        Stop
                    </button>
                </div>
            </div>

            <div class="glass-panel p-6 rounded-2xl shadow-xl flex flex-col gap-4 h-full">
                <div class="border-b border-slate-700 pb-3 flex justify-between items-center">
                    <h2 class="text-lg font-bold text-white flex items-center gap-2">
                        <svg class="w-5 h-5 text-emerald-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"/></svg>
                        Speech to Text
                    </h2>
                    <span id="stt-status" class="text-[10px] font-mono font-bold uppercase text-slate-500">Standby</span>
                </div>

                <div class="flex-1 bg-[#020617] border border-slate-700 rounded-xl p-4 min-h-[220px] relative shadow-inner overflow-y-auto terminal-scroll">
                    <p id="stt-output" class="text-sm text-slate-300 whitespace-pre-wrap leading-relaxed"></p>
                    <p id="stt-interim" class="text-sm text-slate-500 italic mt-2"></p>
                </div>

                <div class="flex gap-3 mt-2">
                    <button id="btn-listen" onclick="toggleDictation()" class="flex-1 bg-emerald-600 hover:bg-emerald-500 text-white font-bold py-3 rounded-xl transition-all shadow-lg border border-emerald-500 text-sm flex justify-center items-center gap-2">
                        <span id="mic-icon" class="w-3 h-3 rounded-full bg-white"></span>
                        <span id="btn-listen-text">Start Dictation</span>
                    </button>
                    <button onclick="copyTranscript()" class="bg-slate-800 hover:bg-slate-700 text-slate-300 font-bold px-4 py-3 rounded-xl transition-all border border-slate-600 text-sm" title="Copy to Clipboard">
                        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z"/></svg>
                    </button>
                    <button onclick="downloadTranscript()" class="bg-slate-800 hover:bg-slate-700 text-slate-300 font-bold px-4 py-3 rounded-xl transition-all border border-slate-600 text-sm" title="Download Text File">
                        .TXT
                    </button>
                </div>
            </div>

        </div>

        <article class="mt-12 flex flex-col gap-8 border-t border-slate-800 pt-12">
            <section class="prose prose-invert prose-slate max-w-none glass-panel p-8 md:p-10 rounded-2xl shadow-xl">
                <h2 class="text-white text-2xl font-bold mb-4">Browser-Native Speech Processing</h2>
                <p class="text-sm text-slate-300 leading-relaxed mb-6">
                    Most modern dictation tools and voice synthesizers rely on external cloud servers. When you speak, your audio file is recorded, uploaded to a remote data center, transcribed by an artificial intelligence model, and the text is sent back to your device. This process requires a constant internet connection and presents a significant privacy concern for sensitive data.
                </p>
                <p class="text-sm text-slate-300 leading-relaxed mb-6">
                    This utility bypasses cloud processing entirely by utilizing the <strong>Web Speech API</strong>, a standard built directly into modern web browsers (such as Google Chrome, Safari, and Edge). 
                </p>

                <div class="grid md:grid-cols-2 gap-6 mt-8">
                    <div class="bg-slate-900/50 p-6 rounded-xl border border-slate-700">
                        <h3 class="text-emerald-400 font-bold mb-2">Speech Recognition (Dictation)</h3>
                        <p class="text-xs text-slate-400 leading-relaxed">
                            Uses the <code>SpeechRecognition</code> interface to capture audio from your local microphone. The browser's internal engine translates the phonetic sounds into text strings. Continuous listening is enabled, meaning the API will automatically pause and resume as you form sentences.
                        </p>
                    </div>
                    <div class="bg-slate-900/50 p-6 rounded-xl border border-slate-700">
                        <h3 class="text-blue-400 font-bold mb-2">Speech Synthesis (TTS)</h3>
                        <p class="text-xs text-slate-400 leading-relaxed">
                            Uses the <code>SpeechSynthesis</code> interface to convert written text into spoken audio. The voices available in the dropdown menu are not downloaded from the internet; they are the physical voice profiles installed locally on your operating system (Windows, macOS, iOS, or Android).
                        </p>
                    </div>
                </div>
            </section>
        </article>
    </main>

    <sv-footer base-path=".."></sv-footer>

    <script>
        // ==========================================
        // TEXT TO SPEECH (TTS) LOGIC
        // ==========================================
        const synth = window.speechSynthesis;
        const voiceSelect = document.getElementById('voice-select');
        const rateInput = document.getElementById('rate');
        const pitchInput = document.getElementById('pitch');
        let voices = [];

        function populateVoiceList() {
            voices = synth.getVoices();
            if (voices.length === 0) return;
            
            voiceSelect.innerHTML = '';
            voices.forEach((voice, i) => {
                const option = document.createElement('option');
                option.textContent = `${voice.name} (${voice.lang})`;
                option.value = i;
                voiceSelect.appendChild(option);
            });
        }

        populateVoiceList();
        if (speechSynthesis.onvoiceschanged !== undefined) {
            speechSynthesis.onvoiceschanged = populateVoiceList;
        }

        rateInput.addEventListener('input', () => document.getElementById('rate-val').innerText = rateInput.value);
        pitchInput.addEventListener('input', () => document.getElementById('pitch-val').innerText = pitchInput.value);

        function speakText() {
            if (synth.speaking) {
                console.error('API is currently processing audio.');
                return;
            }
            const text = document.getElementById('tts-input').value;
            if (text !== '') {
                const utterThis = new SpeechSynthesisUtterance(text);
                const selectedVoice = voices[voiceSelect.value];
                if (selectedVoice) utterThis.voice = selectedVoice;
                
                utterThis.pitch = pitchInput.value;
                utterThis.rate = rateInput.value;
                
                synth.speak(utterThis);
            }
        }

        function stopSpeech() {
            synth.cancel();
        }

        // ==========================================
        // SPEECH TO TEXT (STT) LOGIC
        // ==========================================
        const sttOutput = document.getElementById('stt-output');
        const sttInterim = document.getElementById('stt-interim');
        const btnListen = document.getElementById('btn-listen');
        const btnListenText = document.getElementById('btn-listen-text');
        const micIcon = document.getElementById('mic-icon');
        const sttStatus = document.getElementById('stt-status');

        let recognition = null;
        let isRecording = false;
        let finalTranscript = '';

        // Initialize Web Speech API
        if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onresult = (event) => {
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        finalTranscript += event.results[i][0].transcript + ' ';
                    } else {
                        interimTranscript += event.results[i][0].transcript;
                    }
                }
                
                sttOutput.innerText = finalTranscript;
                sttInterim.innerText = interimTranscript;
                sttOutput.parentElement.scrollTop = sttOutput.parentElement.scrollHeight;
            };

            recognition.onerror = (event) => {
                console.error("Speech API Error:", event.error);
                if (event.error === 'not-allowed') {
                    stopDictation();
                    alert("Microphone access denied. Please allow microphone permissions in your browser settings.");
                }
            };

            // Fix for the continuous prompting bug: 
            // Add a short delay before attempting to restart the listener.
            recognition.onend = () => {
                if (isRecording) {
                    setTimeout(() => {
                        try { recognition.start(); } catch(e) {}
                    }, 250);
                }
            };
        } else {
            sttOutput.innerText = "Error: Your browser does not natively support the Web Speech API. Please use a modern browser like Chrome, Edge, or Safari.";
            btnListen.disabled = true;
            btnListen.classList.add('opacity-50', 'cursor-not-allowed');
        }

        function toggleDictation() {
            if (isRecording) {
                stopDictation();
            } else {
                startDictation();
            }
        }

        function startDictation() {
            if (!recognition) return;
            isRecording = true;
            finalTranscript = sttOutput.innerText; 
            
            try { recognition.start(); } catch(e) {}
            
            btnListen.className = "flex-1 bg-rose-600 hover:bg-rose-500 text-white font-bold py-3 rounded-xl transition-all shadow-[0_0_15px_rgba(225,29,72,0.3)] border border-rose-500 text-sm flex justify-center items-center gap-2";
            btnListenText.innerText = "Stop Dictation";
            micIcon.className = "w-3 h-3 rounded-full bg-white recording-pulse";
            
            sttStatus.innerText = "Listening...";
            sttStatus.className = "text-[10px] font-mono font-bold uppercase text-rose-500 animate-pulse";
        }

        function stopDictation() {
            if (!recognition) return;
            isRecording = false;
            recognition.stop();
            sttInterim.innerText = '';
            
            btnListen.className = "flex-1 bg-emerald-600 hover:bg-emerald-500 text-white font-bold py-3 rounded-xl transition-all shadow-lg border border-emerald-500 text-sm flex justify-center items-center gap-2";
            btnListenText.innerText = "Start Dictation";
            micIcon.className = "w-3 h-3 rounded-full bg-white";
            
            sttStatus.innerText = "Standby";
            sttStatus.className = "text-[10px] font-mono font-bold uppercase text-slate-500";
        }

        function copyTranscript() {
            const text = sttOutput.innerText;
            if (!text) return;
            navigator.clipboard.writeText(text).then(() => {
                const orig = sttStatus.innerText;
                const origClass = sttStatus.className;
                
                sttStatus.innerText = "Copied to Clipboard!";
                sttStatus.className = "text-[10px] font-mono font-bold uppercase text-blue-400";
                
                setTimeout(() => {
                    if (isRecording) {
                        sttStatus.innerText = "Listening...";
                        sttStatus.className = "text-[10px] font-mono font-bold uppercase text-rose-500 animate-pulse";
                    } else {
                        sttStatus.innerText = "Standby";
                        sttStatus.className = "text-[10px] font-mono font-bold uppercase text-slate-500";
                    }
                }, 2000);
            });
        }

        function downloadTranscript() {
            const text = sttOutput.innerText;
            if (!text) return;
            const blob = new Blob([text], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `SilenVault_Transcription_${new Date().getTime()}.txt`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }
    </script>
</body>
</html>
